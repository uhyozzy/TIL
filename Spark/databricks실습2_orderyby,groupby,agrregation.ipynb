{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "191fe31e-bc96-4a00-98bc-720b0bff8f6e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## titanic_train.csv 파일을 로드하고, 이를 DataFrame으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ee26e14-dac0-422e-a752-c85b1504d50c",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>3</td><td>Braund, Mr. Owen Harris</td><td>male</td><td>22.0</td><td>1</td><td>0</td><td>A/5 21171</td><td>7.25</td><td>null</td><td>S</td></tr><tr><td>2</td><td>1</td><td>1</td><td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>PC 17599</td><td>71.2833</td><td>C85</td><td>C</td></tr><tr><td>3</td><td>1</td><td>3</td><td>Heikkinen, Miss. Laina</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>STON/O2. 3101282</td><td>7.925</td><td>null</td><td>S</td></tr><tr><td>4</td><td>1</td><td>1</td><td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>113803</td><td>53.1</td><td>C123</td><td>S</td></tr><tr><td>5</td><td>0</td><td>3</td><td>Allen, Mr. William Henry</td><td>male</td><td>35.0</td><td>0</td><td>0</td><td>373450</td><td>8.05</td><td>null</td><td>S</td></tr><tr><td>6</td><td>0</td><td>3</td><td>Moran, Mr. James</td><td>male</td><td>null</td><td>0</td><td>0</td><td>330877</td><td>8.4583</td><td>null</td><td>Q</td></tr><tr><td>7</td><td>0</td><td>1</td><td>McCarthy, Mr. Timothy J</td><td>male</td><td>54.0</td><td>0</td><td>0</td><td>17463</td><td>51.8625</td><td>E46</td><td>S</td></tr><tr><td>8</td><td>0</td><td>3</td><td>Palsson, Master. Gosta Leonard</td><td>male</td><td>2.0</td><td>3</td><td>1</td><td>349909</td><td>21.075</td><td>null</td><td>S</td></tr><tr><td>9</td><td>1</td><td>3</td><td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td><td>female</td><td>27.0</td><td>0</td><td>2</td><td>347742</td><td>11.1333</td><td>null</td><td>S</td></tr><tr><td>10</td><td>1</td><td>2</td><td>Nasser, Mrs. Nicholas (Adele Achem)</td><td>female</td><td>14.0</td><td>1</td><td>0</td><td>237736</td><td>30.0708</td><td>null</td><td>C</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         0,
         3,
         "Braund, Mr. Owen Harris",
         "male",
         22.0,
         1,
         0,
         "A/5 21171",
         7.25,
         null,
         "S"
        ],
        [
         2,
         1,
         1,
         "Cumings, Mrs. John Bradley (Florence Briggs Thayer)",
         "female",
         38.0,
         1,
         0,
         "PC 17599",
         71.2833,
         "C85",
         "C"
        ],
        [
         3,
         1,
         3,
         "Heikkinen, Miss. Laina",
         "female",
         26.0,
         0,
         0,
         "STON/O2. 3101282",
         7.925,
         null,
         "S"
        ],
        [
         4,
         1,
         1,
         "Futrelle, Mrs. Jacques Heath (Lily May Peel)",
         "female",
         35.0,
         1,
         0,
         "113803",
         53.1,
         "C123",
         "S"
        ],
        [
         5,
         0,
         3,
         "Allen, Mr. William Henry",
         "male",
         35.0,
         0,
         0,
         "373450",
         8.05,
         null,
         "S"
        ],
        [
         6,
         0,
         3,
         "Moran, Mr. James",
         "male",
         null,
         0,
         0,
         "330877",
         8.4583,
         null,
         "Q"
        ],
        [
         7,
         0,
         1,
         "McCarthy, Mr. Timothy J",
         "male",
         54.0,
         0,
         0,
         "17463",
         51.8625,
         "E46",
         "S"
        ],
        [
         8,
         0,
         3,
         "Palsson, Master. Gosta Leonard",
         "male",
         2.0,
         3,
         1,
         "349909",
         21.075,
         null,
         "S"
        ],
        [
         9,
         1,
         3,
         "Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)",
         "female",
         27.0,
         0,
         2,
         "347742",
         11.1333,
         null,
         "S"
        ],
        [
         10,
         1,
         2,
         "Nasser, Mrs. Nicholas (Adele Achem)",
         "female",
         14.0,
         1,
         0,
         "237736",
         30.0708,
         null,
         "C"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "PassengerId",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Survived",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Pclass",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Sex",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "SibSp",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Parch",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Ticket",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Fare",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Cabin",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Embarked",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#spark.read.csv() 메소드를 이용하여 csv 파일을 로드하고 DataFrame으로 변환. \n",
    "# pandas_df = pd.read_csv('/FileStore/tables/titanic_train.csv', header='infer')\n",
    "titanic_sdf = spark.read.csv('/FileStore/tables/titanic_train.csv', header=True, inferSchema=True)\n",
    "\n",
    "# pandas DataFrame을 spark DataFrame으로 부터 생성. \n",
    "titanic_pdf = titanic_sdf.select('*').toPandas()\n",
    "display(titanic_sdf.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1082f77a-818d-40fc-a748-a5ad8aa8521a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- PassengerId: integer (nullable = true)\n |-- Survived: integer (nullable = true)\n |-- Pclass: integer (nullable = true)\n |-- Name: string (nullable = true)\n |-- Sex: string (nullable = true)\n |-- Age: double (nullable = true)\n |-- SibSp: integer (nullable = true)\n |-- Parch: integer (nullable = true)\n |-- Ticket: string (nullable = true)\n |-- Fare: double (nullable = true)\n |-- Cabin: string (nullable = true)\n |-- Embarked: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "titanic_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86516e36-9834-47dd-b701-a5825f71cf0f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## spark DataFrame의 orderBy() 알아보기\n",
    "- spark DataFrame의 orderBy() 메소드는 1개 이상의 컬럼순으로 정렬할 수 있는 기능. orderBy() 결과는 DataFrame으로 반환.\n",
    "- 정렬 컬럼은 문자열, 또는 컬럼 형태로 입력할 수 있으며, 정렬 컬럼이 여러개일 경우 개별 컬럼을 인자로 넣거나 list로도 넣을 수 있음.\n",
    "- 오름차순, 내림차순 구분은 ascending=True/False로 구분\n",
    "- 정렬 컬럼이 여러개 일때 개별 컬럼별로 서로 다른 정렬 옵션을 적용할 경우(예를 들어 컬럼1은 오름차순, 컬럼2는 내림차순) ascending=[True, False]와 같은 형태로 이용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7d9c940-8c4d-4574-8391-74894bb76dd8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Name 컬럼으로 오름차순으로 정렬 \n",
    "titanic_pdf_sorted_01 = titanic_pdf.sort_values(by=['Name'], ascending=True)\n",
    "\n",
    "# Pclass와 Name 컬럼으로 내림차순 정렬\n",
    "titanic_pdf_sorted_02 = titanic_pdf.sort_values(by=['Pclass', 'Name'], ascending=False)\n",
    "\n",
    "# Pclass는 오름차순, Name은 내림차순 정렬\n",
    "titanic_pdf_sorted_03 = titanic_pdf.sort_values(by=['Pclass', 'Name'], ascending=[True, False])\n",
    "display(titanic_pdf_sorted_01)\n",
    "display(titanic_pdf_sorted_02)\n",
    "display(titanic_pdf_sorted_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bb8d89e-3037-4d4a-90d9-1a6c27d5d966",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orderBy에 컬럼명을 문자열로 지정하고 내림 차순 정렬\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+--------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|    Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+--------+-----+--------+\n|        869|       0|     3|van Melkebeke, Mr...|  male|null|    0|    0|          345777|     9.5| null|       S|\n|        154|       0|     3|van Billiard, Mr....|  male|40.5|    0|    2|        A/5. 851|    14.5| null|       S|\n|        362|       0|     2|del Carlo, Mr. Se...|  male|29.0|    1|    0|   SC/PARIS 2167| 27.7208| null|       C|\n|        283|       0|     3|de Pelsmaeker, Mr...|  male|16.0|    0|    0|          345778|     9.5| null|       S|\n|        287|       1|     3|de Mulder, Mr. Th...|  male|30.0|    0|    0|          345774|     9.5| null|       S|\n|        560|       1|     3|de Messemaeker, M...|female|36.0|    1|    0|          345572|    17.4| null|       S|\n|        423|       0|     3|  Zimmerman, Mr. Leo|  male|29.0|    0|    0|          315082|   7.875| null|       S|\n|        241|       0|     3|Zabour, Miss. Tha...|female|null|    1|    0|            2665| 14.4542| null|       C|\n|        112|       0|     3|Zabour, Miss. Hileni|female|14.5|    1|    0|            2665| 14.4542| null|       C|\n|        496|       0|     3|Yousseff, Mr. Ger...|  male|null|    0|    0|            2627| 14.4583| null|       C|\n|        355|       0|     3|   Yousif, Mr. Wazli|  male|null|    0|    0|            2647|   7.225| null|       C|\n|        204|       0|     3|Youseff, Mr. Gerious|  male|45.5|    0|    0|            2628|   7.225| null|       C|\n|        326|       1|     1|Young, Miss. Mari...|female|36.0|    0|    0|        PC 17760|135.6333|  C32|       C|\n|        831|       1|     3|Yasbeck, Mrs. Ant...|female|15.0|    1|    0|            2659| 14.4542| null|       C|\n|        621|       0|     3| Yasbeck, Mr. Antoni|  male|27.0|    1|    0|            2659| 14.4542| null|       C|\n|        556|       0|     1|  Wright, Mr. George|  male|62.0|    0|    0|          113807|   26.55| null|       S|\n|         56|       1|     1|   Woolner, Mr. Hugh|  male|null|    0|    0|           19947|    35.5|  C52|       S|\n|        426|       0|     3|Wiseman, Mr. Phil...|  male|null|    0|    0|      A/4. 34244|    7.25| null|       S|\n|        492|       0|     3| Windelov, Mr. Einar|  male|21.0|    0|    0|SOTON/OQ 3101317|    7.25| null|       S|\n|        352|       0|     1|Williams-Lambert,...|  male|null|    0|    0|          113510|    35.0| C128|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+--------+-----+--------+\nonly showing top 20 rows\n\norderBy에 컬럼명을 DataFrame['컬럼명'] 컬럼형태로 오름 차순 정렬\n+-----------+--------+------+--------------------+------+----+-----+-----+----------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|    Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------+-------+-----+--------+\n|        147|       1|     3|\"Andersson, Mr. A...|  male|27.0|    0|    0|    350043| 7.7958| null|       S|\n|        519|       1|     2|\"Angle, Mrs. Will...|female|36.0|    1|    0|    226875|   26.0| null|       S|\n|        291|       1|     1|\"Barber, Miss. El...|female|26.0|    0|    0|     19877|  78.85| null|       S|\n|        625|       0|     3|\"Bowen, Mr. David...|  male|21.0|    0|    0|     54636|   16.1| null|       S|\n|        508|       1|     1|\"Bradley, Mr. Geo...|  male|null|    0|    0|    111427|  26.55| null|       S|\n|        346|       1|     2|\"Brown, Miss. Ame...|female|24.0|    0|    0|    248733|   13.0|  F33|       S|\n|        209|       1|     3|\"Carr, Miss. Hele...|female|16.0|    0|    0|    367231|   7.75| null|       Q|\n|        205|       1|     3|\"Cohen, Mr. Gursh...|  male|18.0|    0|    0|  A/5 3540|   8.05| null|       S|\n|        238|       1|     2|\"Collyer, Miss. M...|female| 8.0|    0|    2|C.A. 31921|  26.25| null|       S|\n|        490|       1|     3|\"Coutts, Master. ...|  male| 9.0|    1|    1|C.A. 37671|   15.9| null|       S|\n|        349|       1|     3|\"Coutts, Master. ...|  male| 3.0|    1|    1|C.A. 37671|   15.9| null|       S|\n|        557|       1|     1|\"Duff Gordon, Lad...|female|48.0|    1|    0|     11755|   39.6|  A16|       C|\n|        600|       1|     1|\"Duff Gordon, Sir...|  male|49.0|    1|    0|  PC 17485|56.9292|  A20|       C|\n|        573|       1|     1|\"Flynn, Mr. John ...|  male|36.0|    0|    0|  PC 17474|26.3875|  E25|       S|\n|        437|       0|     3|\"Ford, Miss. Dool...|female|21.0|    2|    2|W./C. 6608| 34.375| null|       S|\n|        148|       0|     3|\"Ford, Miss. Robi...|female| 9.0|    2|    2|W./C. 6608| 34.375| null|       S|\n|        482|       0|     2|\"Frost, Mr. Antho...|  male|null|    0|    0|    239854|    0.0| null|       S|\n|        157|       1|     3|\"Gilnagh, Miss. K...|female|16.0|    0|    0|     35851| 7.7333| null|       Q|\n|        166|       1|     3|\"Goldsmith, Maste...|  male| 9.0|    0|    2|    363291| 20.525| null|       S|\n|        721|       1|     2|\"Harper, Miss. An...|female| 6.0|    0|    1|    248727|   33.0| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------+-------+-----+--------+\nonly showing top 20 rows\n\norderBy에 컬럼명을 DataFrame.컬럼명 컬럼형태로 내림 차순 정렬\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+--------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|    Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+--------+-----+--------+\n|        869|       0|     3|van Melkebeke, Mr...|  male|null|    0|    0|          345777|     9.5| null|       S|\n|        154|       0|     3|van Billiard, Mr....|  male|40.5|    0|    2|        A/5. 851|    14.5| null|       S|\n|        362|       0|     2|del Carlo, Mr. Se...|  male|29.0|    1|    0|   SC/PARIS 2167| 27.7208| null|       C|\n|        283|       0|     3|de Pelsmaeker, Mr...|  male|16.0|    0|    0|          345778|     9.5| null|       S|\n|        287|       1|     3|de Mulder, Mr. Th...|  male|30.0|    0|    0|          345774|     9.5| null|       S|\n|        560|       1|     3|de Messemaeker, M...|female|36.0|    1|    0|          345572|    17.4| null|       S|\n|        423|       0|     3|  Zimmerman, Mr. Leo|  male|29.0|    0|    0|          315082|   7.875| null|       S|\n|        241|       0|     3|Zabour, Miss. Tha...|female|null|    1|    0|            2665| 14.4542| null|       C|\n|        112|       0|     3|Zabour, Miss. Hileni|female|14.5|    1|    0|            2665| 14.4542| null|       C|\n|        496|       0|     3|Yousseff, Mr. Ger...|  male|null|    0|    0|            2627| 14.4583| null|       C|\n|        355|       0|     3|   Yousif, Mr. Wazli|  male|null|    0|    0|            2647|   7.225| null|       C|\n|        204|       0|     3|Youseff, Mr. Gerious|  male|45.5|    0|    0|            2628|   7.225| null|       C|\n|        326|       1|     1|Young, Miss. Mari...|female|36.0|    0|    0|        PC 17760|135.6333|  C32|       C|\n|        831|       1|     3|Yasbeck, Mrs. Ant...|female|15.0|    1|    0|            2659| 14.4542| null|       C|\n|        621|       0|     3| Yasbeck, Mr. Antoni|  male|27.0|    1|    0|            2659| 14.4542| null|       C|\n|        556|       0|     1|  Wright, Mr. George|  male|62.0|    0|    0|          113807|   26.55| null|       S|\n|         56|       1|     1|   Woolner, Mr. Hugh|  male|null|    0|    0|           19947|    35.5|  C52|       S|\n|        426|       0|     3|Wiseman, Mr. Phil...|  male|null|    0|    0|      A/4. 34244|    7.25| null|       S|\n|        492|       0|     3| Windelov, Mr. Einar|  male|21.0|    0|    0|SOTON/OQ 3101317|    7.25| null|       S|\n|        352|       0|     1|Williams-Lambert,...|  male|null|    0|    0|          113510|    35.0| C128|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+--------+-----+--------+\nonly showing top 20 rows\n\norderBy에 컬럼명을 col('컬럼명') 컬럼형태로 오름 차순 정렬\n+-----------+--------+------+--------------------+------+----+-----+-----+----------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|    Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------+-------+-----+--------+\n|        147|       1|     3|\"Andersson, Mr. A...|  male|27.0|    0|    0|    350043| 7.7958| null|       S|\n|        519|       1|     2|\"Angle, Mrs. Will...|female|36.0|    1|    0|    226875|   26.0| null|       S|\n|        291|       1|     1|\"Barber, Miss. El...|female|26.0|    0|    0|     19877|  78.85| null|       S|\n|        625|       0|     3|\"Bowen, Mr. David...|  male|21.0|    0|    0|     54636|   16.1| null|       S|\n|        508|       1|     1|\"Bradley, Mr. Geo...|  male|null|    0|    0|    111427|  26.55| null|       S|\n|        346|       1|     2|\"Brown, Miss. Ame...|female|24.0|    0|    0|    248733|   13.0|  F33|       S|\n|        209|       1|     3|\"Carr, Miss. Hele...|female|16.0|    0|    0|    367231|   7.75| null|       Q|\n|        205|       1|     3|\"Cohen, Mr. Gursh...|  male|18.0|    0|    0|  A/5 3540|   8.05| null|       S|\n|        238|       1|     2|\"Collyer, Miss. M...|female| 8.0|    0|    2|C.A. 31921|  26.25| null|       S|\n|        490|       1|     3|\"Coutts, Master. ...|  male| 9.0|    1|    1|C.A. 37671|   15.9| null|       S|\n|        349|       1|     3|\"Coutts, Master. ...|  male| 3.0|    1|    1|C.A. 37671|   15.9| null|       S|\n|        557|       1|     1|\"Duff Gordon, Lad...|female|48.0|    1|    0|     11755|   39.6|  A16|       C|\n|        600|       1|     1|\"Duff Gordon, Sir...|  male|49.0|    1|    0|  PC 17485|56.9292|  A20|       C|\n|        573|       1|     1|\"Flynn, Mr. John ...|  male|36.0|    0|    0|  PC 17474|26.3875|  E25|       S|\n|        437|       0|     3|\"Ford, Miss. Dool...|female|21.0|    2|    2|W./C. 6608| 34.375| null|       S|\n|        148|       0|     3|\"Ford, Miss. Robi...|female| 9.0|    2|    2|W./C. 6608| 34.375| null|       S|\n|        482|       0|     2|\"Frost, Mr. Antho...|  male|null|    0|    0|    239854|    0.0| null|       S|\n|        157|       1|     3|\"Gilnagh, Miss. K...|female|16.0|    0|    0|     35851| 7.7333| null|       Q|\n|        166|       1|     3|\"Goldsmith, Maste...|  male| 9.0|    0|    2|    363291| 20.525| null|       S|\n|        721|       1|     2|\"Harper, Miss. An...|female| 6.0|    0|    1|    248727|   33.0| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------+-------+-----+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# orderBy에 컬럼명을 문자열로 지정. \n",
    "print(\"orderBy에 컬럼명을 문자열로 지정하고 내림 차순 정렬\")\n",
    "titanic_sdf.orderBy(\"Name\", ascending=False).show() # select * from titanic_sdf order by Name desc\n",
    "\n",
    "# orderBy에 컬럼명을 컬럼형태로 지정.\n",
    "print(\"orderBy에 컬럼명을 DataFrame['컬럼명'] 컬럼형태로 오름 차순 정렬\")\n",
    "titanic_sdf.orderBy(titanic_sdf['Name'], ascending=True).show() # select * from titanic_sdf order by Name asc\n",
    "\n",
    "print('orderBy에 컬럼명을 DataFrame.컬럼명 컬럼형태로 내림 차순 정렬')\n",
    "titanic_sdf.orderBy(titanic_sdf.Name, ascending=False).show()\n",
    "\n",
    "print(\"orderBy에 컬럼명을 col('컬럼명') 컬럼형태로 오름 차순 정렬\")\n",
    "titanic_sdf.orderBy(col('Name'), ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5d8acb3-4f9e-417f-9210-d61573544f87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orderBy에 여러개의 컬럼명을 문자열로 지정하고 내림 차순 정렬\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|        869|       0|     3|van Melkebeke, Mr...|  male|null|    0|    0|          345777|    9.5| null|       S|\n|        154|       0|     3|van Billiard, Mr....|  male|40.5|    0|    2|        A/5. 851|   14.5| null|       S|\n|        283|       0|     3|de Pelsmaeker, Mr...|  male|16.0|    0|    0|          345778|    9.5| null|       S|\n|        287|       1|     3|de Mulder, Mr. Th...|  male|30.0|    0|    0|          345774|    9.5| null|       S|\n|        560|       1|     3|de Messemaeker, M...|female|36.0|    1|    0|          345572|   17.4| null|       S|\n|        423|       0|     3|  Zimmerman, Mr. Leo|  male|29.0|    0|    0|          315082|  7.875| null|       S|\n|        241|       0|     3|Zabour, Miss. Tha...|female|null|    1|    0|            2665|14.4542| null|       C|\n|        112|       0|     3|Zabour, Miss. Hileni|female|14.5|    1|    0|            2665|14.4542| null|       C|\n|        496|       0|     3|Yousseff, Mr. Ger...|  male|null|    0|    0|            2627|14.4583| null|       C|\n|        355|       0|     3|   Yousif, Mr. Wazli|  male|null|    0|    0|            2647|  7.225| null|       C|\n|        204|       0|     3|Youseff, Mr. Gerious|  male|45.5|    0|    0|            2628|  7.225| null|       C|\n|        831|       1|     3|Yasbeck, Mrs. Ant...|female|15.0|    1|    0|            2659|14.4542| null|       C|\n|        621|       0|     3| Yasbeck, Mr. Antoni|  male|27.0|    1|    0|            2659|14.4542| null|       C|\n|        426|       0|     3|Wiseman, Mr. Phil...|  male|null|    0|    0|      A/4. 34244|   7.25| null|       S|\n|        492|       0|     3| Windelov, Mr. Einar|  male|21.0|    0|    0|SOTON/OQ 3101317|   7.25| null|       S|\n|        736|       0|     3|Williams, Mr. Leslie|  male|28.5|    0|    0|           54636|   16.1| null|       S|\n|        649|       0|     3|  Willey, Mr. Edward|  male|null|    0|    0|   S.O./P.P. 751|   7.55| null|       S|\n|        372|       0|     3|Wiklund, Mr. Jako...|  male|18.0|    1|    0|         3101267| 6.4958| null|       S|\n|        407|       0|     3|Widegren, Mr. Car...|  male|51.0|    0|    0|          347064|   7.75| null|       S|\n|        512|       0|     3|   Webber, Mr. James|  male|null|    0|    0|SOTON/OQ 3101316|   8.05| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|        869|       0|     3|van Melkebeke, Mr...|  male|null|    0|    0|          345777|    9.5| null|       S|\n|        154|       0|     3|van Billiard, Mr....|  male|40.5|    0|    2|        A/5. 851|   14.5| null|       S|\n|        283|       0|     3|de Pelsmaeker, Mr...|  male|16.0|    0|    0|          345778|    9.5| null|       S|\n|        287|       1|     3|de Mulder, Mr. Th...|  male|30.0|    0|    0|          345774|    9.5| null|       S|\n|        560|       1|     3|de Messemaeker, M...|female|36.0|    1|    0|          345572|   17.4| null|       S|\n|        423|       0|     3|  Zimmerman, Mr. Leo|  male|29.0|    0|    0|          315082|  7.875| null|       S|\n|        241|       0|     3|Zabour, Miss. Tha...|female|null|    1|    0|            2665|14.4542| null|       C|\n|        112|       0|     3|Zabour, Miss. Hileni|female|14.5|    1|    0|            2665|14.4542| null|       C|\n|        496|       0|     3|Yousseff, Mr. Ger...|  male|null|    0|    0|            2627|14.4583| null|       C|\n|        355|       0|     3|   Yousif, Mr. Wazli|  male|null|    0|    0|            2647|  7.225| null|       C|\n|        204|       0|     3|Youseff, Mr. Gerious|  male|45.5|    0|    0|            2628|  7.225| null|       C|\n|        831|       1|     3|Yasbeck, Mrs. Ant...|female|15.0|    1|    0|            2659|14.4542| null|       C|\n|        621|       0|     3| Yasbeck, Mr. Antoni|  male|27.0|    1|    0|            2659|14.4542| null|       C|\n|        426|       0|     3|Wiseman, Mr. Phil...|  male|null|    0|    0|      A/4. 34244|   7.25| null|       S|\n|        492|       0|     3| Windelov, Mr. Einar|  male|21.0|    0|    0|SOTON/OQ 3101317|   7.25| null|       S|\n|        736|       0|     3|Williams, Mr. Leslie|  male|28.5|    0|    0|           54636|   16.1| null|       S|\n|        649|       0|     3|  Willey, Mr. Edward|  male|null|    0|    0|   S.O./P.P. 751|   7.55| null|       S|\n|        372|       0|     3|Wiklund, Mr. Jako...|  male|18.0|    1|    0|         3101267| 6.4958| null|       S|\n|        407|       0|     3|Widegren, Mr. Car...|  male|51.0|    0|    0|          347064|   7.75| null|       S|\n|        512|       0|     3|   Webber, Mr. James|  male|null|    0|    0|SOTON/OQ 3101316|   8.05| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\norderBy에 여러개의 컬럼명을 컬럼형태로 지정하고 내림 차순 정렬\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n|        869|       0|     3|van Melkebeke, Mr...|  male|null|    0|    0|          345777|    9.5| null|       S|\n|        154|       0|     3|van Billiard, Mr....|  male|40.5|    0|    2|        A/5. 851|   14.5| null|       S|\n|        283|       0|     3|de Pelsmaeker, Mr...|  male|16.0|    0|    0|          345778|    9.5| null|       S|\n|        287|       1|     3|de Mulder, Mr. Th...|  male|30.0|    0|    0|          345774|    9.5| null|       S|\n|        560|       1|     3|de Messemaeker, M...|female|36.0|    1|    0|          345572|   17.4| null|       S|\n|        423|       0|     3|  Zimmerman, Mr. Leo|  male|29.0|    0|    0|          315082|  7.875| null|       S|\n|        241|       0|     3|Zabour, Miss. Tha...|female|null|    1|    0|            2665|14.4542| null|       C|\n|        112|       0|     3|Zabour, Miss. Hileni|female|14.5|    1|    0|            2665|14.4542| null|       C|\n|        496|       0|     3|Yousseff, Mr. Ger...|  male|null|    0|    0|            2627|14.4583| null|       C|\n|        355|       0|     3|   Yousif, Mr. Wazli|  male|null|    0|    0|            2647|  7.225| null|       C|\n|        204|       0|     3|Youseff, Mr. Gerious|  male|45.5|    0|    0|            2628|  7.225| null|       C|\n|        831|       1|     3|Yasbeck, Mrs. Ant...|female|15.0|    1|    0|            2659|14.4542| null|       C|\n|        621|       0|     3| Yasbeck, Mr. Antoni|  male|27.0|    1|    0|            2659|14.4542| null|       C|\n|        426|       0|     3|Wiseman, Mr. Phil...|  male|null|    0|    0|      A/4. 34244|   7.25| null|       S|\n|        492|       0|     3| Windelov, Mr. Einar|  male|21.0|    0|    0|SOTON/OQ 3101317|   7.25| null|       S|\n|        736|       0|     3|Williams, Mr. Leslie|  male|28.5|    0|    0|           54636|   16.1| null|       S|\n|        649|       0|     3|  Willey, Mr. Edward|  male|null|    0|    0|   S.O./P.P. 751|   7.55| null|       S|\n|        372|       0|     3|Wiklund, Mr. Jako...|  male|18.0|    1|    0|         3101267| 6.4958| null|       S|\n|        407|       0|     3|Widegren, Mr. Car...|  male|51.0|    0|    0|          347064|   7.75| null|       S|\n|        512|       0|     3|   Webber, Mr. James|  male|null|    0|    0|SOTON/OQ 3101316|   8.05| null|       S|\n+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "print(\"orderBy에 여러개의 컬럼명을 문자열로 지정하고 내림 차순 정렬\")\n",
    "titanic_sdf.orderBy(\"Pclass\", \"Name\", ascending=False).show()\n",
    "titanic_sdf.orderBy([\"Pclass\", \"Name\"], ascending=False).show()\n",
    "\n",
    "print(\"orderBy에 여러개의 컬럼명을 컬럼형태로 지정하고 내림 차순 정렬\")\n",
    "titanic_sdf.orderBy(col(\"Pclass\"), col(\"Name\"), ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0174c07a-d8a3-4a36-aacb-f0c4804b7528",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orderBy에 여러개의 컬럼명을 문자열로 지정하고 서로 다른 방식으로 정렬 \n+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|    Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\n|        326|       1|     1|Young, Miss. Mari...|female|36.0|    0|    0|PC 17760|135.6333|  C32|       C|\n|        556|       0|     1|  Wright, Mr. George|  male|62.0|    0|    0|  113807|   26.55| null|       S|\n|         56|       1|     1|   Woolner, Mr. Hugh|  male|null|    0|    0|   19947|    35.5|  C52|       S|\n|        352|       0|     1|Williams-Lambert,...|  male|null|    0|    0|  113510|    35.0| C128|       S|\n|        156|       0|     1|Williams, Mr. Cha...|  male|51.0|    0|    1|PC 17597| 61.3792| null|       C|\n|        378|       0|     1|Widener, Mr. Harr...|  male|27.0|    0|    2|  113503|   211.5|  C82|       C|\n|        857|       1|     1|Wick, Mrs. George...|female|45.0|    1|    1|   36928|164.8667| null|       S|\n|        319|       1|     1|Wick, Miss. Mary ...|female|31.0|    0|    2|   36928|164.8667|   C7|       S|\n|        103|       0|     1|White, Mr. Richar...|  male|21.0|    0|    1|   35281| 77.2875|  D26|       S|\n|        125|       0|     1|White, Mr. Perciv...|  male|54.0|    0|    1|   35281| 77.2875|  D26|       S|\n|        695|       0|     1|     Weir, Col. John|  male|60.0|    0|    0|  113800|   26.55| null|       S|\n|        367|       1|     1|Warren, Mrs. Fran...|female|60.0|    1|    0|  110813|   75.25|  D37|       C|\n|        259|       1|     1|    Ward, Miss. Anna|female|35.0|    0|    0|PC 17755|512.3292| null|       C|\n|        516|       0|     1|Walker, Mr. Willi...|  male|47.0|    0|    0|   36967| 34.0208|  D46|       S|\n|        171|       0|     1|Van der hoef, Mr....|  male|61.0|    0|    0|  111240|    33.5|  B19|       S|\n|         31|       0|     1|Uruchurtu, Don. M...|  male|40.0|    0|    0|PC 17601| 27.7208| null|       C|\n|        257|       1|     1|Thorne, Mrs. Gert...|female|null|    0|    0|PC 17585|    79.2| null|       C|\n|        582|       1|     1|Thayer, Mrs. John...|female|39.0|    1|    1|   17421|110.8833|  C68|       C|\n|        551|       1|     1|Thayer, Mr. John ...|  male|17.0|    0|    2|   17421|110.8833|  C70|       C|\n|        699|       0|     1|Thayer, Mr. John ...|  male|49.0|    1|    1|   17421|110.8833|  C68|       C|\n+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\nonly showing top 20 rows\n\norderBy에 여러개의 컬럼명을 컬럼형태로 지정하고 서로 다른 방식으로 정렬 \n+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|    Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\n|        326|       1|     1|Young, Miss. Mari...|female|36.0|    0|    0|PC 17760|135.6333|  C32|       C|\n|        556|       0|     1|  Wright, Mr. George|  male|62.0|    0|    0|  113807|   26.55| null|       S|\n|         56|       1|     1|   Woolner, Mr. Hugh|  male|null|    0|    0|   19947|    35.5|  C52|       S|\n|        352|       0|     1|Williams-Lambert,...|  male|null|    0|    0|  113510|    35.0| C128|       S|\n|        156|       0|     1|Williams, Mr. Cha...|  male|51.0|    0|    1|PC 17597| 61.3792| null|       C|\n|        378|       0|     1|Widener, Mr. Harr...|  male|27.0|    0|    2|  113503|   211.5|  C82|       C|\n|        857|       1|     1|Wick, Mrs. George...|female|45.0|    1|    1|   36928|164.8667| null|       S|\n|        319|       1|     1|Wick, Miss. Mary ...|female|31.0|    0|    2|   36928|164.8667|   C7|       S|\n|        103|       0|     1|White, Mr. Richar...|  male|21.0|    0|    1|   35281| 77.2875|  D26|       S|\n|        125|       0|     1|White, Mr. Perciv...|  male|54.0|    0|    1|   35281| 77.2875|  D26|       S|\n|        695|       0|     1|     Weir, Col. John|  male|60.0|    0|    0|  113800|   26.55| null|       S|\n|        367|       1|     1|Warren, Mrs. Fran...|female|60.0|    1|    0|  110813|   75.25|  D37|       C|\n|        259|       1|     1|    Ward, Miss. Anna|female|35.0|    0|    0|PC 17755|512.3292| null|       C|\n|        516|       0|     1|Walker, Mr. Willi...|  male|47.0|    0|    0|   36967| 34.0208|  D46|       S|\n|        171|       0|     1|Van der hoef, Mr....|  male|61.0|    0|    0|  111240|    33.5|  B19|       S|\n|         31|       0|     1|Uruchurtu, Don. M...|  male|40.0|    0|    0|PC 17601| 27.7208| null|       C|\n|        257|       1|     1|Thorne, Mrs. Gert...|female|null|    0|    0|PC 17585|    79.2| null|       C|\n|        582|       1|     1|Thayer, Mrs. John...|female|39.0|    1|    1|   17421|110.8833|  C68|       C|\n|        551|       1|     1|Thayer, Mr. John ...|  male|17.0|    0|    2|   17421|110.8833|  C70|       C|\n|        699|       0|     1|Thayer, Mr. John ...|  male|49.0|    1|    1|   17421|110.8833|  C68|       C|\n+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\nonly showing top 20 rows\n\n+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|    Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\n|        326|       1|     1|Young, Miss. Mari...|female|36.0|    0|    0|PC 17760|135.6333|  C32|       C|\n|        556|       0|     1|  Wright, Mr. George|  male|62.0|    0|    0|  113807|   26.55| null|       S|\n|         56|       1|     1|   Woolner, Mr. Hugh|  male|null|    0|    0|   19947|    35.5|  C52|       S|\n|        352|       0|     1|Williams-Lambert,...|  male|null|    0|    0|  113510|    35.0| C128|       S|\n|        156|       0|     1|Williams, Mr. Cha...|  male|51.0|    0|    1|PC 17597| 61.3792| null|       C|\n|        378|       0|     1|Widener, Mr. Harr...|  male|27.0|    0|    2|  113503|   211.5|  C82|       C|\n|        857|       1|     1|Wick, Mrs. George...|female|45.0|    1|    1|   36928|164.8667| null|       S|\n|        319|       1|     1|Wick, Miss. Mary ...|female|31.0|    0|    2|   36928|164.8667|   C7|       S|\n|        103|       0|     1|White, Mr. Richar...|  male|21.0|    0|    1|   35281| 77.2875|  D26|       S|\n|        125|       0|     1|White, Mr. Perciv...|  male|54.0|    0|    1|   35281| 77.2875|  D26|       S|\n|        695|       0|     1|     Weir, Col. John|  male|60.0|    0|    0|  113800|   26.55| null|       S|\n|        367|       1|     1|Warren, Mrs. Fran...|female|60.0|    1|    0|  110813|   75.25|  D37|       C|\n|        259|       1|     1|    Ward, Miss. Anna|female|35.0|    0|    0|PC 17755|512.3292| null|       C|\n|        516|       0|     1|Walker, Mr. Willi...|  male|47.0|    0|    0|   36967| 34.0208|  D46|       S|\n|        171|       0|     1|Van der hoef, Mr....|  male|61.0|    0|    0|  111240|    33.5|  B19|       S|\n|         31|       0|     1|Uruchurtu, Don. M...|  male|40.0|    0|    0|PC 17601| 27.7208| null|       C|\n|        257|       1|     1|Thorne, Mrs. Gert...|female|null|    0|    0|PC 17585|    79.2| null|       C|\n|        582|       1|     1|Thayer, Mrs. John...|female|39.0|    1|    1|   17421|110.8833|  C68|       C|\n|        551|       1|     1|Thayer, Mr. John ...|  male|17.0|    0|    2|   17421|110.8833|  C70|       C|\n|        699|       0|     1|Thayer, Mr. John ...|  male|49.0|    1|    1|   17421|110.8833|  C68|       C|\n+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# orderBy에 여러개의 컬럼명을 지정하고 서로 다른 방식으로 정렬하기\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "print(\"orderBy에 여러개의 컬럼명을 문자열로 지정하고 서로 다른 방식으로 정렬 \")\n",
    "titanic_sdf.orderBy('Pclass', 'Name', ascending=[True, False]).show()\n",
    "\n",
    "print(\"orderBy에 여러개의 컬럼명을 컬럼형태로 지정하고 서로 다른 방식으로 정렬 \")\n",
    "titanic_sdf.orderBy(col('Pclass'), col('Name'), ascending=[True, False]).show()\n",
    "\n",
    "# 개별 컬럼별로 asc(), desc()를 적용. \n",
    "titanic_sdf.orderBy(col('Pclass').asc(), col('Name').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e86d414b-8683-4f8f-a949-a7e93da7bfce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\n|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|    Fare|Cabin|Embarked|\n+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\n|        326|       1|     1|Young, Miss. Mari...|female|36.0|    0|    0|PC 17760|135.6333|  C32|       C|\n|        556|       0|     1|  Wright, Mr. George|  male|62.0|    0|    0|  113807|   26.55| null|       S|\n|         56|       1|     1|   Woolner, Mr. Hugh|  male|null|    0|    0|   19947|    35.5|  C52|       S|\n|        352|       0|     1|Williams-Lambert,...|  male|null|    0|    0|  113510|    35.0| C128|       S|\n|        156|       0|     1|Williams, Mr. Cha...|  male|51.0|    0|    1|PC 17597| 61.3792| null|       C|\n|        378|       0|     1|Widener, Mr. Harr...|  male|27.0|    0|    2|  113503|   211.5|  C82|       C|\n|        857|       1|     1|Wick, Mrs. George...|female|45.0|    1|    1|   36928|164.8667| null|       S|\n|        319|       1|     1|Wick, Miss. Mary ...|female|31.0|    0|    2|   36928|164.8667|   C7|       S|\n|        103|       0|     1|White, Mr. Richar...|  male|21.0|    0|    1|   35281| 77.2875|  D26|       S|\n|        125|       0|     1|White, Mr. Perciv...|  male|54.0|    0|    1|   35281| 77.2875|  D26|       S|\n|        695|       0|     1|     Weir, Col. John|  male|60.0|    0|    0|  113800|   26.55| null|       S|\n|        367|       1|     1|Warren, Mrs. Fran...|female|60.0|    1|    0|  110813|   75.25|  D37|       C|\n|        259|       1|     1|    Ward, Miss. Anna|female|35.0|    0|    0|PC 17755|512.3292| null|       C|\n|        516|       0|     1|Walker, Mr. Willi...|  male|47.0|    0|    0|   36967| 34.0208|  D46|       S|\n|        171|       0|     1|Van der hoef, Mr....|  male|61.0|    0|    0|  111240|    33.5|  B19|       S|\n|         31|       0|     1|Uruchurtu, Don. M...|  male|40.0|    0|    0|PC 17601| 27.7208| null|       C|\n|        257|       1|     1|Thorne, Mrs. Gert...|female|null|    0|    0|PC 17585|    79.2| null|       C|\n|        582|       1|     1|Thayer, Mrs. John...|female|39.0|    1|    1|   17421|110.8833|  C68|       C|\n|        551|       1|     1|Thayer, Mr. John ...|  male|17.0|    0|    2|   17421|110.8833|  C70|       C|\n|        699|       0|     1|Thayer, Mr. John ...|  male|49.0|    1|    1|   17421|110.8833|  C68|       C|\n+-----------+--------+------+--------------------+------+----+-----+-----+--------+--------+-----+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# orderBy()와 동일한 메소드로 sort()를 제공. \n",
    "titanic_sdf.sort(col('Pclass').asc(), col('Name').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8266cb1-5a8e-4cd3-bb5c-b84445be7398",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n|Pclass|                Name|\n+------+--------------------+\n|     1|Young, Miss. Mari...|\n|     1|  Wright, Mr. George|\n|     1|   Woolner, Mr. Hugh|\n|     1|Williams-Lambert,...|\n|     1|Williams, Mr. Cha...|\n|     1|Widener, Mr. Harr...|\n|     1|Wick, Mrs. George...|\n|     1|Wick, Miss. Mary ...|\n|     1|White, Mr. Richar...|\n|     1|White, Mr. Perciv...|\n|     1|     Weir, Col. John|\n|     1|Warren, Mrs. Fran...|\n|     1|    Ward, Miss. Anna|\n|     1|Walker, Mr. Willi...|\n|     1|Van der hoef, Mr....|\n|     1|Uruchurtu, Don. M...|\n|     1|Thorne, Mrs. Gert...|\n|     1|Thayer, Mrs. John...|\n|     1|Thayer, Mr. John ...|\n|     1|Thayer, Mr. John ...|\n+------+--------------------+\nonly showing top 20 rows\n\n+------+--------------------+\n|Pclass|                Name|\n+------+--------------------+\n|     1|Young, Miss. Mari...|\n|     1|  Wright, Mr. George|\n|     1|   Woolner, Mr. Hugh|\n|     1|Williams-Lambert,...|\n|     1|Williams, Mr. Cha...|\n|     1|Widener, Mr. Harr...|\n|     1|Wick, Mrs. George...|\n|     1|Wick, Miss. Mary ...|\n|     1|White, Mr. Richar...|\n|     1|White, Mr. Perciv...|\n|     1|     Weir, Col. John|\n|     1|Warren, Mrs. Fran...|\n|     1|    Ward, Miss. Anna|\n|     1|Walker, Mr. Willi...|\n|     1|Van der hoef, Mr....|\n|     1|Uruchurtu, Don. M...|\n|     1|Thorne, Mrs. Gert...|\n|     1|Thayer, Mrs. John...|\n|     1|Thayer, Mr. John ...|\n|     1|Thayer, Mr. John ...|\n+------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# select Pclass, Name from titanic_sdf order by Pclass asc, Name desc\n",
    "titanic_sdf.select(col('Pclass'), col('Name')).orderBy(col('Pclass').asc(), col('Name').desc()).show()\n",
    "\n",
    "#select Pclass, Name from (select * from titanic_sdf order by Pclass asc, Name desc)\n",
    "titanic_sdf.orderBy(col('Pclass').asc(), col('Name').desc()).select(col('Pclass'), col('Name')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ab11b51-842b-436f-88df-46ee295e62a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## spark DataFrame에 aggregation(집계) 메소드 적용하기\n",
    "- pandas DataFrame은 DataFrame 객체에서 aggregation 메소드를 많이 가질 수 있음(DataFrame.count(), DataFrame.max())\n",
    "- pandas DataFrame은 DataFrame 객체에 aggregation 메소드를 적용 시 DataFrame에 속한 전체 컬럼들에 모두 aggregation 메소드를 적용\n",
    "- spark DataFrame은 DataFrame 객체에서 aggregation 메소드를 별로 가지고 있지 않음. count() 메소드 정도...\n",
    "- spark DataFrame에 aggregation 메소드를 적용 시에는 pyspark.sql.functions 모듈의 max, min, sum 등의 함수를 이용해야함.\n",
    "- pandas와 spark에서 agrregation 방식이 다르고, 맞게 사용하지 않을 시 에러가 나기 때문에 주의해서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f0b7012-dcec-4f86-8ce1-be763bafd7da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### pandas dataframe count() aggregation ####\nPassengerId    891\nSurvived       891\nPclass         891\nName           891\nSex            891\nAge            714\nSibSp          891\nParch          891\nTicket         891\nFare           891\nCabin          204\nEmbarked       889\ndtype: int64\n#### pandas dataframe max() aggregation ####\nPassengerId                            891\nSurvived                                 1\nPclass                                   3\nName           van Melkebeke, Mr. Philemon\nSex                                   male\nAge                                   80.0\nSibSp                                    8\nParch                                    6\nTicket                           WE/P 5735\nFare                              512.3292\ndtype: object\n#### pandas dataframe count() aggregation 결과 type ####\n<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<command-418230295219946>:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n  print(titanic_pdf.max())\n"
     ]
    }
   ],
   "source": [
    "print('#### pandas dataframe count() aggregation ####')\n",
    "print(titanic_pdf.count())\n",
    "\n",
    "print('#### pandas dataframe max() aggregation ####')\n",
    "print(titanic_pdf.max())\n",
    "\n",
    "print('#### pandas dataframe count() aggregation 결과 type ####')\n",
    "print(type(titanic_pdf.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1acd6b91-dbe8-478b-807d-7aeb666bc4a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass     3.0\nAge       80.0\ndtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(titanic_pdf[['Pclass', 'Age']].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953ea92b-c7b3-465b-9d2c-8c444daa905a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 결과: 891\n"
     ]
    }
   ],
   "source": [
    "# spark DataFrame에 count() aggregation을 적용하면 DataFrame의 Record 건수 반환. \n",
    "print('count 결과:', titanic_sdf.count()) # select count(*) from titanic_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4569231-3790-41d2-a8e5-94c7f1836af4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-418230295219943>:4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 하지만 count() 가 아닌 다른 aggregation 함수를 DataFrame에 적용하면 오류 발생.이는 SQL과 유사\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# 이는 count() aggregation 함수가 가진 특수성. 다른 aggregation 함수들은 어떤 컬럼을 aggregation 할지\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# count()외의 다른 aggregation 함수, 예를 들어 max(), min()등은 pyspark.sql.functions 모듈에 별도로 \u001B[39;00m\n",
       "\u001B[0;32m----> 4\u001B[0m \u001B[43mtitanic_sdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2964\u001B[0m, in \u001B[0;36mDataFrame.__getattr__\u001B[0;34m(self, name)\u001B[0m\n",
       "\u001B[1;32m   2934\u001B[0m \u001B[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001B[39;00m\n",
       "\u001B[1;32m   2935\u001B[0m \n",
       "\u001B[1;32m   2936\u001B[0m \u001B[38;5;124;03m.. versionadded:: 1.3.0\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   2961\u001B[0m \u001B[38;5;124;03m+---+\u001B[39;00m\n",
       "\u001B[1;32m   2962\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m   2963\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns:\n",
       "\u001B[0;32m-> 2964\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n",
       "\u001B[1;32m   2965\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name)\n",
       "\u001B[1;32m   2966\u001B[0m     )\n",
       "\u001B[1;32m   2967\u001B[0m jc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mapply(name)\n",
       "\u001B[1;32m   2968\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Column(jc)\n",
       "\n",
       "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'max'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-418230295219943>:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 하지만 count() 가 아닌 다른 aggregation 함수를 DataFrame에 적용하면 오류 발생.이는 SQL과 유사\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# 이는 count() aggregation 함수가 가진 특수성. 다른 aggregation 함수들은 어떤 컬럼을 aggregation 할지\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# count()외의 다른 aggregation 함수, 예를 들어 max(), min()등은 pyspark.sql.functions 모듈에 별도로 \u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[43mtitanic_sdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2964\u001B[0m, in \u001B[0;36mDataFrame.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   2934\u001B[0m \u001B[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001B[39;00m\n\u001B[1;32m   2935\u001B[0m \n\u001B[1;32m   2936\u001B[0m \u001B[38;5;124;03m.. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2961\u001B[0m \u001B[38;5;124;03m+---+\u001B[39;00m\n\u001B[1;32m   2962\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2963\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[0;32m-> 2964\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[1;32m   2965\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name)\n\u001B[1;32m   2966\u001B[0m     )\n\u001B[1;32m   2967\u001B[0m jc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mapply(name)\n\u001B[1;32m   2968\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Column(jc)\n\n\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'max'",
       "errorSummary": "<span class='ansi-red-fg'>AttributeError</span>: 'DataFrame' object has no attribute 'max'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 하지만 count() 가 아닌 다른 aggregation 함수를 DataFrame에 적용하면 오류 발생.이는 SQL과 유사\n",
    "titanic_sdf.max() # select max() from titanic_sdf 와 같은 SQL을 구문 오류. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da236e35-3727-4dae-879a-f49f854caaa2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|max(Age)|\n+--------+\n|    80.0|\n+--------+\n\nNone\n<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max, sum, min # agrregation함수를 import해서 사용해야함 \n",
    "# spark DataFrame에 count()를 제외하고 max(), min(), sum(), avg()와 같은 aggregate 메소드를 바로 호출\n",
    "titanic_sdf_max = titanic_sdf.select(max('Age')) # select max(Age) from titanic_sdf\n",
    "print(titanic_sdf_max.show())\n",
    "print(type(titanic_sdf_max)) # max() aggregation은 단 한개의 값을 반환하지만 DataFrame으로 반환. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1512905a-d987-4b64-8941-d1b0f4f895ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## spark DataFrame의 groupBy() 알아 보기\n",
    "- pandas DataFrame의 groupby(by='group_by_컬럼명') 수행 시 group_by_컬럼명 레벨로 group by 된 DataFrameGroupBy 객체 반환하고 여기에 aggregation 메소드 적용.\n",
    "- spark DataFrame도 groupBy('group_by_컬럼명') 수행 시 group_by_컬럼명 레벨로 group by 된 GroupedData 객체 반환하고 여기에 aggregation 메소드 적용.\n",
    "- pandas DataFrameGroupBy 객체에 agg() 메소드를 이용하여 서로 다른 컬럼에 서로 다른 aggregation 함수 적용 가능\n",
    "- spark GroupedData 객체도 agg() 메소드를 이용하여 서로 다른 컬럼에 서로 다른 aggregation 함수 적용 가능\n",
    "- spark groupBy()는 pandas groupby()의 특징과 SQL의 특징을 함께 가짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b935ebd9-1889-415b-826a-6dbad1d6ffca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas DataFrame의 groupby() 적용 결과 type: <class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n\n#### group by 레벨로 모든 컬럼에 count 적용 #### \n        PassengerId  Survived  Name  Sex  Age  SibSp  Parch  Ticket  Fare  \\\nPclass                                                                      \n1               216       216   216  216  186    216    216     216   216   \n2               184       184   184  184  173    184    184     184   184   \n3               491       491   491  491  355    491    491     491   491   \n\n        Cabin  Embarked  \nPclass                   \n1         176       214  \n2          16       184  \n3          12       491  \n\n#### group by 레벨로 특정 컬럼에 aggregation 적용 #### \nPclass\n1    80.0\n2    70.0\n3    74.0\nName: Age, dtype: float64\n\n#### group by 레벨로 여러 컬럼에 동일 aggregation 적용 #### \n         Age      Fare\nPclass                \n1       80.0  512.3292\n2       70.0   73.5000\n3       74.0   69.5500\n\n#### group by 레벨로 여러개의 aggregation 함수를 서로 다른 컬럼에 적용 #### \n         Age  SibSp       Fare\nPclass                        \n1       80.0     90  84.154687\n2       70.0     74  20.662183\n3       74.0    302  13.675550\n"
     ]
    }
   ],
   "source": [
    "# pandas DataFrame에 groupby()메소드 호출 시 DataFrameGroupBy 객체 반환. \n",
    "titanic_pdf_groupby = titanic_pdf.groupby(by='Pclass')\n",
    "print('pandas DataFrame의 groupby() 적용 결과 type:', type(titanic_pdf_groupby))\n",
    "\n",
    "# Group by 된 pandas DataFrameGroupBy 객체에 count()를 적용 시 group by 된 컬럼값 레벨로 모든 컬럼들에 적용\n",
    "print('\\n#### group by 레벨로 모든 컬럼에 count 적용 #### ')\n",
    "print(titanic_pdf.groupby(by='Pclass').count())\n",
    "print('\\n#### group by 레벨로 특정 컬럼에 aggregation 적용 #### ')\n",
    "\n",
    "# Group by 된 pandas DataFrameGroupBy 객체에 특정 컬럼에 aggregation 을 적용하려면 해당 컬럼을 ['컬럼'].max()\n",
    "print(titanic_pdf.groupby(by='Pclass')['Age'].max()) # select max(Age) from titanic_pdf group by Pcl\n",
    "\n",
    "# pandas DataFrameGroupBy 객체에 여러 컬럼에 동일 aggregation 을 적용하려면 해당 컬럼들을 [['컬럼명1','컬럼명2']].max()\n",
    "print('\\n#### group by 레벨로 여러 컬럼에 동일 aggregation 적용 #### ')\n",
    "print(titanic_pdf.groupby(by='Pclass')[['Age', 'Fare']].max()) # select max(Age), max(Fare) from tit\n",
    "\n",
    "# Group by 된 DataFrameGroupBy 객체에 서로 다른 컬럼에 서로 다른 aggregation 함수를 적용하려면 agg()\n",
    "# agg()메소드 내부에 인자는 dictionary 형태로 적용 컬럼명과 적용 aggregation 함수 기재\n",
    "print('\\n#### group by 레벨로 여러개의 aggregation 함수를 서로 다른 컬럼에 적용 #### ')\n",
    "agg_format = {'Age':'max', 'SibSp':'sum', 'Fare':'mean'}\n",
    "print(titanic_pdf.groupby(by='Pclass').agg(agg_format))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d105df15-faef-4089-89fc-003a285de6eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    491\n1    216\n2    184\nName: Pclass, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pandas DataFrame의 value_counts()는 Series에 적용시 해당 series내의 값 별로 건수를 구함. \n",
    "print(titanic_pdf['Pclass'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c357620d-4bfa-4858-aa19-490fb1325fcc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n|Pclass|count|\n+------+-----+\n|     1|  216|\n|     3|  491|\n|     2|  184|\n+------+-----+\n\nspark DataFrame groupBy type: <class 'pyspark.sql.group.GroupedData'>\nspark GroupedData의 aggregation 메소드 적용 결과 type: DataFrame[Pclass: int, count: bigint]\n"
     ]
    }
   ],
   "source": [
    "# pandas 의 value_counts()의 대응될 수 있는 groupBy() 메소드. Spark DataFrame에 groupBy() 적용 시 Gr\n",
    "# GroupedData Object에 count()외에 min(), max(), avg(), sum() 등 다양한 aggregation 메소드를 호출하여\n",
    "titanic_sdf.groupBy('Pclass').count().show() # select pclass, count(*) from titanic_sdf group by pcl\n",
    "print('spark DataFrame groupBy type:', type(titanic_sdf.groupBy('Pclass')))\n",
    "print('spark GroupedData의 aggregation 메소드 적용 결과 type:', titanic_sdf.groupBy('Pclass').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2da912e-dfbe-4fc0-b6c5-c3560fcedb6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n|Pclass|count|\n+------+-----+\n|     3|  491|\n|     1|  216|\n|     2|  184|\n+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# spark DataFrame의 orderBy()메소드를 적용하여 group by 결과 건수 descending 으로 정렬 \n",
    "titanic_sdf.groupBy('Pclass').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98e38f55-05e7-4f33-88b7-33b2847edcef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+-------------+-----------+--------+----------+----------+---------+\n|Pclass|max(PassengerId)|max(Survived)|max(Pclass)|max(Age)|max(SibSp)|max(Parch)|max(Fare)|\n+------+----------------+-------------+-----------+--------+----------+----------+---------+\n|     1|             890|            1|          1|    80.0|         3|         4| 512.3292|\n|     3|             891|            1|          3|    74.0|         8|         6|    69.55|\n|     2|             887|            1|          2|    70.0|         3|         3|     73.5|\n+------+----------------+-------------+-----------+--------+----------+----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "#GroupedData 에 count()가 아니고 다른 aggregation 메소드를 적용 시 pandas DataFrame의 groupby와 유사\n",
    "titanic_sdf.groupBy('Pclass').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40f83fa8-6806-45cd-b7b3-494372ddf448",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n|Pclass|max(Age)|\n+------+--------+\n|     1|    80.0|\n|     3|    74.0|\n|     2|    70.0|\n+------+--------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-418230295219953>:5\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m titanic_sdf\u001B[38;5;241m.\u001B[39mgroupBy(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPclass\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAge\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mshow() \u001B[38;5;66;03m# select max(Age) from titainic_sdf group by Pclass\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#GroupedData에서 aggregation 메소드 호출 시 오직 문자열 컬럼명만 가능. 컬럼형 인자 입력은 오류 발생.\u001B[39;00m\n",
       "\u001B[0;32m----> 5\u001B[0m titanic_sdf\u001B[38;5;241m.\u001B[39mgroupBy(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPclass\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmax(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAge\u001B[39m\u001B[38;5;124m'\u001B[39m))\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/group.py:49\u001B[0m, in \u001B[0;36mdf_varargs_api.<locals>._api\u001B[0;34m(self, *cols)\u001B[0m\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_api\u001B[39m(\u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGroupedData\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n",
       "\u001B[1;32m     48\u001B[0m     name \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n",
       "\u001B[0;32m---> 49\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jgd, name)(\u001B[43m_to_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m)\n",
       "\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:89\u001B[0m, in \u001B[0;36m_to_seq\u001B[0;34m(sc, cols, converter)\u001B[0m\n",
       "\u001B[1;32m     87\u001B[0m     cols \u001B[38;5;241m=\u001B[39m [converter(c) \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m cols]\n",
       "\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m sc\u001B[38;5;241m.\u001B[39m_jvm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPythonUtils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoSeq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n",
       "\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n",
       "\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n",
       "\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:511\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n",
       "\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n",
       "\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n",
       "\u001B[0;32m--> 511\u001B[0m     \u001B[43mjava_list\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43melement\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n",
       "\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n",
       "\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n",
       "\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n",
       "\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:510\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n",
       "\u001B[1;32m    508\u001B[0m ArrayList \u001B[38;5;241m=\u001B[39m JavaClass(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjava.util.ArrayList\u001B[39m\u001B[38;5;124m\"\u001B[39m, gateway_client)\n",
       "\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n",
       "\u001B[0;32m--> 510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n",
       "\u001B[1;32m    511\u001B[0m     java_list\u001B[38;5;241m.\u001B[39madd(element)\n",
       "\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:657\u001B[0m, in \u001B[0;36mColumn.__iter__\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 657\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn is not iterable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: Column is not iterable"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-418230295219953>:5\u001B[0m\n\u001B[1;32m      2\u001B[0m titanic_sdf\u001B[38;5;241m.\u001B[39mgroupBy(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPclass\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmax(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAge\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mshow() \u001B[38;5;66;03m# select max(Age) from titainic_sdf group by Pclass\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#GroupedData에서 aggregation 메소드 호출 시 오직 문자열 컬럼명만 가능. 컬럼형 인자 입력은 오류 발생.\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m titanic_sdf\u001B[38;5;241m.\u001B[39mgroupBy(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPclass\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmax(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAge\u001B[39m\u001B[38;5;124m'\u001B[39m))\u001B[38;5;241m.\u001B[39mshow()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/group.py:49\u001B[0m, in \u001B[0;36mdf_varargs_api.<locals>._api\u001B[0;34m(self, *cols)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_api\u001B[39m(\u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGroupedData\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[1;32m     48\u001B[0m     name \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[0;32m---> 49\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jgd, name)(\u001B[43m_to_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession)\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:89\u001B[0m, in \u001B[0;36m_to_seq\u001B[0;34m(sc, cols, converter)\u001B[0m\n\u001B[1;32m     87\u001B[0m     cols \u001B[38;5;241m=\u001B[39m [converter(c) \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m cols]\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m sc\u001B[38;5;241m.\u001B[39m_jvm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPythonUtils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtoSeq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:511\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n\u001B[1;32m    510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n\u001B[0;32m--> 511\u001B[0m     \u001B[43mjava_list\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43melement\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1313\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m-> 1313\u001B[0m     args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_args\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1315\u001B[0m     command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m         args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m         proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m     answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1277\u001B[0m, in \u001B[0;36mJavaMember._build_args\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_args\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconverters) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1277\u001B[0m         (new_args, temp_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_args\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1278\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1279\u001B[0m         new_args \u001B[38;5;241m=\u001B[39m args\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1264\u001B[0m, in \u001B[0;36mJavaMember._get_args\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m   1262\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m converter \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39mconverters:\n\u001B[1;32m   1263\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter\u001B[38;5;241m.\u001B[39mcan_convert(arg):\n\u001B[0;32m-> 1264\u001B[0m         temp_arg \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m         temp_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\u001B[1;32m   1266\u001B[0m         new_args\u001B[38;5;241m.\u001B[39mappend(temp_arg)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_collections.py:510\u001B[0m, in \u001B[0;36mListConverter.convert\u001B[0;34m(self, object, gateway_client)\u001B[0m\n\u001B[1;32m    508\u001B[0m ArrayList \u001B[38;5;241m=\u001B[39m JavaClass(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjava.util.ArrayList\u001B[39m\u001B[38;5;124m\"\u001B[39m, gateway_client)\n\u001B[1;32m    509\u001B[0m java_list \u001B[38;5;241m=\u001B[39m ArrayList()\n\u001B[0;32m--> 510\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mobject\u001B[39m:\n\u001B[1;32m    511\u001B[0m     java_list\u001B[38;5;241m.\u001B[39madd(element)\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m java_list\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:657\u001B[0m, in \u001B[0;36mColumn.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 657\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn is not iterable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\n\u001B[0;31mTypeError\u001B[0m: Column is not iterable",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: Column is not iterable",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# group by 레벨로 특정 컬럼에 aggregation 적용. max('컬럼명')과 같이 aggregation 메소드 내부에 인자로\n",
    "titanic_sdf.groupBy('Pclass').max('Age').show() # select max(Age) from titainic_sdf group by Pclass\n",
    "\n",
    "#GroupedData에서 aggregation 메소드 호출 시 오직 문자열 컬럼명만 가능. 컬럼형 인자 입력은 오류 발생.\n",
    "titanic_sdf.groupBy('Pclass').max(col('Age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7eaf003-391d-4ec2-aa3d-e68bee2ada8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+\n|Pclass|   Sex|max(Age)|\n+------+------+--------+\n|     2|female|    57.0|\n|     3|  male|    74.0|\n|     1|  male|    80.0|\n|     3|female|    63.0|\n|     1|female|    63.0|\n|     2|  male|    70.0|\n+------+------+--------+\n\n+------+------+--------+\n|Pclass|   Sex|max(Age)|\n+------+------+--------+\n|     2|female|    57.0|\n|     3|  male|    74.0|\n|     1|  male|    80.0|\n|     3|female|    63.0|\n|     1|female|    63.0|\n|     2|  male|    70.0|\n+------+------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# 여러 컬럼으로 Group by 규정할 때 개별 컬럼명을 입력하거나, list 형태로 입력 가능. \n",
    "titanic_sdf.groupBy('Pclass', 'Sex').max('Age').show() # select max(Age) from titanic_sdf group by Pclass, Sex\n",
    "titanic_sdf.groupBy(['Pclass', 'Sex']).max('Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5688043-3563-4511-9033-fa0644e2ba3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+--------+------------------+\n|Pclass|max(Age)|min(Age)|sum(Age)|          avg(Age)|\n+------+--------+--------+--------+------------------+\n|     1|    80.0|    0.92| 7111.42|38.233440860215055|\n|     3|    74.0|    0.42| 8924.92| 25.14061971830986|\n|     2|    70.0|    0.67| 5168.83| 29.87763005780347|\n+------+--------+--------+--------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "### 여러개의 aggregation 함수를 적용할 경우는 agg()메소드 내에서 개별 aggregation 함수를 명시 해야함\n",
    "from pyspark.sql.functions import max, avg, sum, min\n",
    "\n",
    "# select max(age), min(age), sum(age), avg(age) from titanic_sdf group by pclass\n",
    "titanic_sdf.groupBy('Pclass').agg(max('Age'), min('Age'), sum('Age'), avg('Age')).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d90656f-49e6-40b0-b9c4-6e95114448b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+------------------+\n|Pclass|max_age|min_age|sum_age|           avg_age|\n+------+-------+-------+-------+------------------+\n|     1|   80.0|   0.92|7111.42|38.233440860215055|\n|     3|   74.0|   0.42|8924.92| 25.14061971830986|\n|     2|   70.0|   0.67|5168.83| 29.87763005780347|\n+------+-------+-------+-------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#아래와 같이 개별 aggregation 함수 결과 컬럼에 별도의 컬럼명을 alias('새로운 컬럼명')을 활용하여 부여\n",
    "# agg() 메소드 내에서 aggregation 함수 적용 시에는 col('컬럼명')과 같은 컬럼형으로 컬럼명을 지정해도\n",
    "# select max(age) as max_age, min(age) as min_age, sum(age) as sum_age, avg(age) as avg_age from tit\n",
    "\n",
    "titanic_sdf.groupBy('Pclass').agg(\n",
    " max(col('Age')).alias('max_age'), min('Age').alias('min_age'), \\\n",
    " sum('Age').alias('sum_age'), avg('Age').alias('avg_age') \\\n",
    " ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0320b75-4a08-45e2-94a9-c8a74e15f2c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+------------------+\n|Pclass|max_age|min_age|sum_age|           avg_age|\n+------+-------+-------+-------+------------------+\n|     1|   80.0|   0.92|7111.42|38.233440860215055|\n|     3|   74.0|   0.42|8924.92| 25.14061971830986|\n+------+-------+-------+-------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 아래와 같이 filter()를 적용하여 group by의 aggregation 결과 값을 기준으로 filtering 적용할 수 있음\n",
    "\n",
    "titanic_sdf.groupBy('Pclass').agg(max(col('Age')).alias('max_age'), min('Age').alias('min_age') , \\\n",
    " sum('Age').alias('sum_age'), avg('Age').alias('avg_age') \\\n",
    " ).filter(col('max_age') > 70).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "databricks실습2_orderyby,groupby,agrregation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
