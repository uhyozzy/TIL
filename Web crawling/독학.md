>id: #

> class: . 

# 1. 원하는 태그 선택하기 BeautifulSoup
```python
import requests
from bs4 import BeautifulSoup

 
response = requests.get("https://www.naver.com/") # 네이버 서버에 대화를 시도

html = response.text # naver에서 html을 줌 

soup = BeautifulSoup(html, 'html.parser') #html 번역선생님(parser)로 Soup를 만듦

word = soup.select_one('#NM_set_home_btn') # id 값이 NM_set_home_btn인 것 한개를 찾아 냄

print(word.text) #text요소만 출력 
```

## 활용) 네이버 뉴스제목&링크 크롤링
```python
import requests
from bs4 import BeautifulSoup

response = requests.get("웹사이트 주소")
html = response.text

soup = BeautifulSoup(html, 'html.parser')
links = soup.select("가져오려는 class 혹은 id") 
print(links) #결과는 리스트로 출력

for link in links:
	title = link.text
	url = link.attrs['href'] #href의 속성값을 가져옴
	print(title, url)
```
# 2. 검색어에 따라 다른 결과를 나타내기 : pyautogui
## 2-1. URL 이란?
![image](https://github.com/uhyozzy/TIL/assets/134241881/7742c053-55f6-4679-b1f2-210b00f732a5)
```
프로토콜 : http or https
도메인 : ip주소에 이름을 부여한 것 
path : 서버에서 해당 페이지의 경로를 나타냄
parameter
	: 각 파라미터는 key와 value로 구성됨
	: 서버에 추가적인 정보를 제공하기 위해 활용 
	: query는 검색의 값 
```

## 2-2. 검색어 변경하기 
```python
import requests
from bs4 import BeautifulSoup

keyword= input("검색어를 입력하세요>>>")
response = requests.get("~~&query=" + keyword)
html = response.text

soup = BeautifulSoup(html, 'html.parser')
links = soup.select("가져오려는 class 혹은 id") 
print(links) #결과는 리스트로 출력

for link in links:
	title = link.text
	url = link.attrs['href'] #href의 속성값을 가져옴
	print(title, url)
``` 
## 2-3. pyautogui 라이브러리
```python
pip install pyautogui로 설치

import requests
from bs4 import BeautifulSoup
import pyautogui

keyword= pyautogui.prompt("검색어를 입력하세요>>>")
response = requests.get(f"~~&query={keyword}") # 문자열 기호 앞에 f를 쓰고 변수가 들어가는 자리에 {변수}
html = response.text

soup = BeautifulSoup(html, 'html.parser')
links = soup.select("가져오려는 class 혹은 id") 
print(links) #결과는 리스트로 출력

for link in links:
	title = link.text
	url = link.attrs['href'] #href의 속성값을 가져옴
	print(title, url)

```
# 3. 여러 페이지 결과 가져오기 : 반복문
> for i in range(시작, 끝, 단계):

> 예) for i in range(1, 10, 2):
	1, 3, 5, 7, 9 가 i에 한번씩 들어감

```python
import requests
from bs4 import BeautifulSoup
import pyautogui

keyword= pyautogui.prompt("검색어를 입력하세요>>>")
lastpage = pyautogui.prompt("마지막 페이지 번호를 입력해주세요") # 사용자로부터 페이지 수 입력받기
pageNum = 1 # 페이지 넘버 정보 추가 
for i in range(1, int(lastpage*10), 10):	#사용자한테 받은건 문자열이므로 정수로 변환해주어야 함
	print(f"{pageNum}페이지 입니다.==========")
	response = requests.get(f"~~&query={keyword}&start={}") # start파라미터 이용하여 페이지정보 추가
	html = response.text

	soup = BeautifulSoup(html, 'html.parser')
	links = soup.select("가져오려는 class 혹은 id") 
	print(links) #결과는 리스트로 출력

	for link in links:
		title = link.text
		url = link.attrs['href'] #href의 속성값을 가져옴
		print(title, url)
	pageNum = pageNum+1
```

# 4. 네이버 자동로그인
```python
from selenium.webdriver.common.by import by

driver.implicitly_waits(5) # 웹페이지가 로딩 될때까지는 5초 기다림 
driver.maximize_window() # 화면 최대화 
driver.get("https://nid.naver.com/nidlogin.login?mode=form&url=https://www.naver.com/")

# 아이디 입력창
id = driver.find_element(By.CSS_SELECTOR, "#id")
id.click
id.send_keys("아이디") # 키보드를 입력

# 비밀번호 입력창
id = driver.find_element(By.CSS_SELECTOR, "#pw")
id.click
id.send_keys("비밀번호") # 키보드를 입력

# 로그인버튼 클릭
login_btn = driver.find_element(By.CSS_SELECTOR, "#log\.login")
login_btn.click

```

```python

# selenium
```python
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chorme.options import Options

# 크롬 드라이버 자동 업데이트
from webdriver_manager.chrome import ChromeDriverManager

service = Service(excutable_path=ChromeDriverManager().install())
driver = webdriver.Chrome(service=service)


# 웹페이지 해당 주소 이동
driver.get("https://www.naver.com")

# 브라우저 꺼짐 방지
chrome_options = Options()
chrome_options.add_experimental_option("detach", True)

# 불필요한 에러 메시지 없애기
chrome_opotions.add_experimental_option("excludeSwithces", ["enable-logging"])

```
