# 1.1.1 Melon크롤링 결과를 Excel에 저장하기 
```ptyhon

from selenium import webdriver
from bs4 import BeautifulSoup


from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager


driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))

## driver = webdriver.Chrome('C:/Myexam/chromedriver/chromedriver.exe')


# 멜론사이트 접속하기
url = 'http://www.melon.com/chart/index.htm'
driver.get(url)

html = driver.page_source
soup = BeautifulSoup(html,'html.parser')


# 반복문을 이용해 곡과 가수명을 song_data에 저장하기 
song_data = []
rank = 1

songs = soup.select('table > tbody > tr')
for song in songs:
    title = song.select('div.rank01 > span > a')[0].text
    singer = song.select('div.rank02 > a')[0].text
    song_data.append(['Melon', rank, title, singer])
    rank = rank + 1


# song_data 리스트를 이용해 데이터프레임 만들기
import pandas as pd
columns = ['서비스', '순위', '타이틀', '가수']
pd_data = pd.DataFrame(song_data, columns = columns)
pd_data.head()



# 크롤링 결과를 엑셀파일에 저장하기
pd_data.to_excel('./files.melon.xlsx', index=False)




```

# 1.1.2 Bugs 크롤링 결과를 Excel에 저장하기 
```ptyhon
from selenium import webdriver
from bs4 import BeautifulSoup

from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager

driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))

# 벅스 사이트 접속하기
from selenium import webdriver
from bs4 import BeautifulSoup


url = 'https://music.bugs.co.kr/chart'
driver.get(url)

html = driver.page_source
soup = BeautifulSoup(html, 'html.parser')

# tr 태그로 곡 정보찾기 1
songs = soup.select('tr')
print(len(songs))

# tr 태그로 곡 정보찾기 2
songs = soup.select('tbody > tr')
print(len(songs))

# tr 태그로 곡 정보찾기 3
songs = soup.select('table > tbody > tr')
print(len(songs))

# tr 태그로 곡 정보찾기 4
songs = soup.select('table.byChart > tbody > tr')
print(len(songs))

# songs 태그 중 첫 번째 태그 출력해보기
print(songs[0])

# 한 개의 곡 정보 저장하기
song = songs[0]

# 벅스 사이트에서 곡 제목 찾기1
title = song.select('a')
len(title)

# 벅스 사이트에서 곡 제목 찾기2
title = song.select('p>a')
len(title)

# 벅스 사이트에서 곡 제목 찾기3
title = song.select('p.title>a')
len(title)

# 벅스 사이트에서 곡 제목 텍스트 출력하기 
title = song.select('p.title>a')[0].text
title

# 벅스 사이트에서 가수 이름 텍스트 출력하기 
singer = song.select('p.artist>a')[0].text.strip()
singer

# 벅스 100위 노래 순위 정보 가져오기
songs = soup.select('table.byChart > tbody > tr')
for song in songs:
    title = song.select('p.title>a')[0].text
    singer = song.select('p.artist >a')[0].text
    print(title, singer, sep='|')

# 반복문을 이용해 곡과 가수명 song_data에 저장하기
song_data = []
rank =1
songs = soup.select('table.byChart > tbody > tr')
for song in songs:
    title = song.select('p.title > a')[0].text
    singer=song.select('p.artist > a')[0].text
    song_data.append(['Bugs', rank, title, singer])
    rank = rank +1

# song_data 리스트를 이용해 데이터프레임 만들기 
import pandas as pd
colunms = ['서비스', '순위', '타이틀', '가수']
pd_data = pd.DataFrame(song_data, columns = columns)
pd_data.info()

# 크롤링 결과를 엑셀 파일로 저장하기
pd_data.to_excel('./files/bugs.xlsx', index=False)


```

# 1.1.3 Genie 크롤링 결과를 Excel에 저장하기 
```ptyhon
from selenium import webdriver
from bs4 import BeautifulSoup

from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager

driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))

# 지니 사이트 접속하기
from selenium import webdriver
from bs4 import BeautifulSoup


url = 'https://www.genie.co.kr/top200'
driver.get(url)

html = driver.page_source
soup = BeautifulSoup(html, 'html.parser')

# 지니 사이트에서 곡 정보 찾기 
songs = soup.select('table > tbody > tr')
len(songs)

# songs 태그 중 첫 번째 태그 출력해보기
print(songs[0])

# 한 개의 곡 정보 저장하기
song = songs[0]

# 벅스 사이트에서 곡 제목 찾기1
title = song.select('a.title')
len(title)

# 지니 사이트에서 곡 제목 텍스트 출력하기 1
title = song.select('a.title')[0].text
title

# 지니 사이트에서 곡 제목 텍스트 출력하기 2
title = song.select('a.title')[0].text.stirp()
title

# 지니 사이트의 가수명 찾기
singer = song.select('a.artist')
len(singer)

# 지니 사이트의 가수명 출력하기
singer = song.select('a.artist')[0].text
singer

# 지니 사이트의 가수명 출력하기2
songs = soup.select('tbody > tr')
for song in songs:
    title = song.select('p.title')[0].text.strip()
    singer = song.select('a.artist')[0].text
    print(title, singer, sep='|')

# 반복문을 이용해 곡과 가수명 song_data에 저장하기
song_data = []
rank =1
songs = soup.select('table > tbody > tr')
for song in songs:
    title = song.select('p.title')[0].text.strip()
    singer = song.select('a.artist')[0].text
    song_data.append(['Genie', rank, title, singer])
    rank = rank + 1


# song_data 리스트를 이용해 엑셀 파일로 저장하기
import pandas as pd
colunms = ['서비스', '순위', '타이틀', '가수']
pd_data = pd.DataFrame(song_data, columns = columns)
pd_data.to_excel('./files/genie.xlsx', index=False)





















```
